{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kYEr9EFejER"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the matchups file\n",
        "matchups = pd.read_csv('womens_matchups_validation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN EARLY ROUNDS MODEL\n",
        "df_early = pd.read_csv('games_early_2_.csv')\n",
        "features_early = ['barthag', 'adj_oe', 'adj_de', 'orb_pct', 'drb_pct', 'ftr', '2p_pct']\n",
        "X = df_early[features_early]\n",
        "y = df_early['win']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "model_early = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_early.fit(X_train, y_train)\n",
        "\n",
        "# TRAIN ELITE ROUNDS MODEL\n",
        "df_elite = pd.read_csv('games_elite_2_.csv')\n",
        "features_elite = ['wab', 'barthag', 'adj_oe', 'adj_de', 'efg_pct', 'efgd_pct', 'orb_pct', 'drb_pct', '2p_pct', '2pd_pct', '3p_pct', '3pd_pct', '3pr']\n",
        "X = df_elite[features_elite]\n",
        "y = df_elite['win']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "model_elite = xgb.XGBClassifier(learning_rate=0.2997738363859162,\n",
        "                                max_depth=9,\n",
        "                                min_child_weight=8.623522034407337,\n",
        "                                subsample=0.8324211691115178,\n",
        "                                colsample_bytree=0.9988769480719698,\n",
        "                                gamma=2.017715776385069,\n",
        "                                reg_alpha=0.9692563913308194,\n",
        "                                reg_lambda=2.5910989850621258,\n",
        "                                n_estimators=335,\n",
        "                                objective='binary:logistic',\n",
        "                                random_state=42,\n",
        "                                use_label_encoder=False)\n",
        "model_elite.fit(X_train, y_train, verbose=False)"
      ],
      "metadata": {
        "id": "VkxVbFdhfgjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which model to use based on round\n",
        "early_rounds = ['First Round', 'Second Round']\n",
        "matchups['model_type'] = matchups['round'].apply(lambda x: 'early' if x in early_rounds else 'elite')\n",
        "\n",
        "# Predict for early rounds\n",
        "early_mask = matchups['model_type'] == 'early'\n",
        "if early_mask.sum() > 0:\n",
        "    X_pred = matchups.loc[early_mask, features_early]\n",
        "    matchups.loc[early_mask, 'predicted_win'] = model_early.predict(X_pred)\n",
        "    matchups.loc[early_mask, 'high_seed_win_prob'] = model_early.predict_proba(X_pred)[:, 1]\n",
        "\n",
        "# Predict for elite rounds\n",
        "elite_mask = matchups['model_type'] == 'elite'\n",
        "if elite_mask.sum() > 0:\n",
        "    X_pred = matchups.loc[elite_mask, features_elite]\n",
        "    matchups.loc[elite_mask, 'predicted_win'] = model_elite.predict(X_pred)\n",
        "    matchups.loc[elite_mask, 'high_seed_win_prob'] = model_elite.predict_proba(X_pred)[:, 1]\n"
      ],
      "metadata": {
        "id": "3tbyjO1Zfouv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matchups['correct'] = (matchups['predicted_win'] == matchups['win']).astype(int)\n",
        "\n",
        "# Export\n",
        "matchups.to_csv('all_matchups_predictions.csv', index=False)\n",
        "print(f\"Predicted {len(matchups)} matchups\")\n",
        "print(f\"Overall Accuracy: {matchups['correct'].mean():.4f}\")\n",
        "print(\"Saved to all_matchups_predictions.csv\")"
      ],
      "metadata": {
        "id": "7oyikb5tfyer"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}