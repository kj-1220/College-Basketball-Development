{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iUXbkjGg7Uo",
        "outputId": "58037477-0d0c-4733-8bcc-dfb60a353d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Round games only: 636 games\n",
            "Train: (508, 108)\n",
            "Test: (128, 108)\n",
            "Total features: 108\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_selection import (\n",
        "    f_classif, mutual_info_classif, SelectKBest,\n",
        "    RFE, SequentialFeatureSelector\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression, LassoCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from scipy import stats\n",
        "from itertools import combinations\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# =============================================================================\n",
        "# DATA LOADING - FIRST ROUND ONLY\n",
        "# =============================================================================\n",
        "\n",
        "df = pd.read_csv('men_2026_matchups_training.csv')\n",
        "\n",
        "# FILTER FOR FIRST ROUND ONLY\n",
        "df = df[df['round'] == 'First Round'].copy()\n",
        "print(f\"First Round games only: {len(df)} games\")\n",
        "\n",
        "metadata_cols = ['Unnamed: 0', 'game_id', 'year', 'region', 'round',\n",
        "                 'high_bracket_team', 'low_bracket_team',\n",
        "                 'high_bracket_seed', 'low_bracket_seed', 'seed']\n",
        "target_col = 'win'\n",
        "feature_cols = [col for col in df.columns if col not in metadata_cols + [target_col]]\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[target_col])\n",
        "\n",
        "X_train = train_df[feature_cols].fillna(0)\n",
        "y_train = train_df[target_col]\n",
        "X_test = test_df[feature_cols].fillna(0)\n",
        "y_test = test_df[target_col]\n",
        "\n",
        "print(f\"Train: {X_train.shape}\")\n",
        "print(f\"Test: {X_test.shape}\")\n",
        "print(f\"Total features: {len(feature_cols)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PART 1: STATISTICAL TESTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PART 1: STATISTICAL TESTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. T-Tests\n",
        "print(\"\\n1. T-TESTS\")\n",
        "print(\"-\" * 80)\n",
        "ttest_results = []\n",
        "for feature in feature_cols:\n",
        "    win_values = X_train[y_train == 1][feature]\n",
        "    loss_values = X_train[y_train == 0][feature]\n",
        "\n",
        "    t_stat, p_value = stats.ttest_ind(win_values, loss_values)\n",
        "\n",
        "    ttest_results.append({\n",
        "        'feature': feature,\n",
        "        't_statistic': t_stat,\n",
        "        'p_value': p_value\n",
        "    })\n",
        "\n",
        "ttest_df = pd.DataFrame(ttest_results).sort_values('t_statistic', ascending=False)\n",
        "print(\"Top 20 features by t-test p-value:\")\n",
        "print(ttest_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HxTesqMhipc",
        "outputId": "997bec7e-8fef-405d-e87f-b5b818f86618"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PART 1: STATISTICAL TESTS\n",
            "================================================================================\n",
            "\n",
            "1. T-TESTS\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by t-test p-value:\n",
            "                            feature  t_statistic       p_value\n",
            "0                          5man_bpm    14.646951  9.426750e-41\n",
            "3                        kenpom_rtg    14.405771  1.130117e-39\n",
            "4                        torvik_rtg    14.397666  1.228145e-39\n",
            "1                          3man_bpm    14.068121  3.555854e-38\n",
            "2                               wab    13.507370  1.009699e-35\n",
            "42                        5man_dbpm    12.992089  1.650941e-33\n",
            "25                        5man_obpm    12.842572  7.115884e-33\n",
            "28                       torvik_off    11.807636  1.378040e-28\n",
            "45                       torvik_def    11.744298  2.484899e-28\n",
            "43                        3man_dbpm    11.685399  4.292642e-28\n",
            "44                       kenpom_def    11.629257  7.217742e-28\n",
            "27                       kenpom_off    11.559995  1.367634e-27\n",
            "26                        3man_obpm    11.392467  6.359560e-27\n",
            "105           def_experience_impact    10.900422  5.379497e-25\n",
            "82   experience_weighted_production    10.886265  6.101595e-25\n",
            "9                              size     7.687110  7.886993e-14\n",
            "106      def_four_factors_composite     6.111882  1.967945e-09\n",
            "83           four_factors_composite     6.008082  3.591586e-09\n",
            "56                def_close2_fg_pct     5.869839  7.898795e-09\n",
            "39                off_close2_fg_pct     5.537063  4.948454e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ANOVA F-test\n",
        "print(\"\\n2. ANOVA F-TEST\")\n",
        "print(\"-\" * 80)\n",
        "f_scores, f_pvalues = f_classif(X_train, y_train)\n",
        "anova_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'f_score': f_scores,\n",
        "    'p_value': f_pvalues\n",
        "}).sort_values('f_score', ascending=False)\n",
        "print(\"Top 20 features by ANOVA F-test:\")\n",
        "print(anova_df.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKUqOmUpkPr0",
        "outputId": "04d6dadb-e0e6-4e56-a2e0-a2f91a59be9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. ANOVA F-TEST\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by ANOVA F-test:\n",
            "                            feature     f_score       p_value\n",
            "0                          5man_bpm  214.533161  9.426750e-41\n",
            "3                        kenpom_rtg  207.526233  1.130117e-39\n",
            "4                        torvik_rtg  207.292782  1.228145e-39\n",
            "1                          3man_bpm  197.912024  3.555854e-38\n",
            "2                               wab  182.449036  1.009699e-35\n",
            "42                        5man_dbpm  168.794389  1.650941e-33\n",
            "25                        5man_obpm  164.931650  7.115884e-33\n",
            "28                       torvik_off  139.420271  1.378040e-28\n",
            "45                       torvik_def  137.928543  2.484899e-28\n",
            "43                        3man_dbpm  136.548541  4.292642e-28\n",
            "44                       kenpom_def  135.239607  7.217742e-28\n",
            "27                       kenpom_off  133.633477  1.367634e-27\n",
            "26                        3man_obpm  129.788302  6.359560e-27\n",
            "87             lineup_depth_quality  120.784421  2.414743e-25\n",
            "105           def_experience_impact  118.819204  5.379497e-25\n",
            "82   experience_weighted_production  118.510764  6.101595e-25\n",
            "107        def_lineup_depth_quality  111.457463  1.106877e-23\n",
            "9                              size   59.091653  7.886993e-14\n",
            "106      def_four_factors_composite   37.355100  1.967945e-09\n",
            "83           four_factors_composite   36.097053  3.591586e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Mutual Information\n",
        "print(\"\\n3. MUTUAL INFORMATION\")\n",
        "print(\"-\" * 80)\n",
        "mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
        "mi_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'mi_score': mi_scores\n",
        "}).sort_values('mi_score', ascending=False)\n",
        "print(\"Top 20 features by Mutual Information:\")\n",
        "print(mi_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3MK7fazk138",
        "outputId": "75cf9b44-2078-4257-ff06-8dbb7d1cb99f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. MUTUAL INFORMATION\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Mutual Information:\n",
            "                            feature  mi_score\n",
            "0                          5man_bpm  0.191502\n",
            "1                          3man_bpm  0.187783\n",
            "2                               wab  0.177098\n",
            "4                        torvik_rtg  0.176688\n",
            "3                        kenpom_rtg  0.167001\n",
            "44                       kenpom_def  0.143659\n",
            "45                       torvik_def  0.138502\n",
            "42                        5man_dbpm  0.135763\n",
            "43                        3man_dbpm  0.135614\n",
            "28                       torvik_off  0.129778\n",
            "27                       kenpom_off  0.127227\n",
            "25                        5man_obpm  0.127104\n",
            "82   experience_weighted_production  0.118627\n",
            "26                        3man_obpm  0.110827\n",
            "105           def_experience_impact  0.102102\n",
            "107        def_lineup_depth_quality  0.100026\n",
            "87             lineup_depth_quality  0.092359\n",
            "34                              tor  0.058566\n",
            "106      def_four_factors_composite  0.049412\n",
            "79            assist_to_usage_ratio  0.048947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Cohen's d (Effect Size)\n",
        "print(\"\\n4. COHEN'S D (EFFECT SIZE)\")\n",
        "print(\"-\" * 80)\n",
        "cohens_d_results = []\n",
        "for feature in feature_cols:\n",
        "    win_values = X_train[y_train == 1][feature]\n",
        "    loss_values = X_train[y_train == 0][feature]\n",
        "\n",
        "    mean_diff = win_values.mean() - loss_values.mean()\n",
        "    pooled_std = np.sqrt(((len(win_values) - 1) * win_values.std()**2 +\n",
        "                          (len(loss_values) - 1) * loss_values.std()**2) /\n",
        "                         (len(win_values) + len(loss_values) - 2))\n",
        "\n",
        "    cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
        "\n",
        "    cohens_d_results.append({\n",
        "        'feature': feature,\n",
        "        'cohens_d': cohens_d,\n",
        "        'abs_cohens_d': abs(cohens_d)\n",
        "    })\n",
        "\n",
        "cohens_df = pd.DataFrame(cohens_d_results).sort_values('abs_cohens_d', ascending=False)\n",
        "print(\"Top 20 features by Cohen's d:\")\n",
        "print(cohens_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oKxtZxRl3FS",
        "outputId": "2ec01023-77b1-42ec-8c6f-4387bee268b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. COHEN'S D (EFFECT SIZE)\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Cohen's d:\n",
            "                            feature  cohens_d  abs_cohens_d\n",
            "0                          5man_bpm  1.299707      1.299707\n",
            "3                        kenpom_rtg  1.278305      1.278305\n",
            "4                        torvik_rtg  1.277586      1.277586\n",
            "1                          3man_bpm  1.248344      1.248344\n",
            "2                               wab  1.198585      1.198585\n",
            "42                        5man_dbpm  1.152862      1.152862\n",
            "25                        5man_obpm  1.139594      1.139594\n",
            "28                       torvik_off  1.047758      1.047758\n",
            "45                       torvik_def  1.042138      1.042138\n",
            "43                        3man_dbpm  1.036911      1.036911\n",
            "44                       kenpom_def  1.031930      1.031930\n",
            "27                       kenpom_off  1.025784      1.025784\n",
            "26                        3man_obpm  1.010918      1.010918\n",
            "87             lineup_depth_quality -0.975222      0.975222\n",
            "105           def_experience_impact  0.967256      0.967256\n",
            "82   experience_weighted_production  0.966000      0.966000\n",
            "107        def_lineup_depth_quality -0.936813      0.936813\n",
            "9                              size  0.682121      0.682121\n",
            "106      def_four_factors_composite  0.542342      0.542342\n",
            "83           four_factors_composite  0.533131      0.533131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Point-Biserial Correlation\n",
        "print(\"\\n5. POINT-BISERIAL CORRELATION\")\n",
        "print(\"-\" * 80)\n",
        "corr_results = []\n",
        "for feature in feature_cols:\n",
        "    corr, p_value = stats.pointbiserialr(y_train, X_train[feature])\n",
        "    corr_results.append({\n",
        "        'feature': feature,\n",
        "        'correlation': corr,\n",
        "        'abs_correlation': abs(corr),\n",
        "        'p_value': p_value\n",
        "    })\n",
        "\n",
        "corr_df = pd.DataFrame(corr_results).sort_values('abs_correlation', ascending=False)\n",
        "print(\"Top 20 features by Point-Biserial Correlation:\")\n",
        "print(corr_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvQwgStomKu6",
        "outputId": "a50858e4-fd7a-4ffc-a7d6-d0154e1c9d84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. POINT-BISERIAL CORRELATION\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Point-Biserial Correlation:\n",
            "                            feature  correlation  abs_correlation  \\\n",
            "0                          5man_bpm     0.545658         0.545658   \n",
            "3                        kenpom_rtg     0.539301         0.539301   \n",
            "4                        torvik_rtg     0.539086         0.539086   \n",
            "1                          3man_bpm     0.530245         0.530245   \n",
            "2                               wab     0.514796         0.514796   \n",
            "42                        5man_dbpm     0.500142         0.500142   \n",
            "25                        5man_obpm     0.495807         0.495807   \n",
            "28                       torvik_off     0.464774         0.464774   \n",
            "45                       torvik_def     0.462816         0.462816   \n",
            "43                        3man_dbpm     0.460989         0.460989   \n",
            "44                       kenpom_def     0.459242         0.459242   \n",
            "27                       kenpom_off     0.457080         0.457080   \n",
            "26                        3man_obpm     0.451816         0.451816   \n",
            "87             lineup_depth_quality    -0.438982         0.438982   \n",
            "105           def_experience_impact     0.436080         0.436080   \n",
            "82   experience_weighted_production     0.435621         0.435621   \n",
            "107        def_lineup_depth_quality    -0.424865         0.424865   \n",
            "9                              size     0.323373         0.323373   \n",
            "106      def_four_factors_composite     0.262200         0.262200   \n",
            "83           four_factors_composite     0.258046         0.258046   \n",
            "\n",
            "          p_value  \n",
            "0    9.426750e-41  \n",
            "3    1.130117e-39  \n",
            "4    1.228145e-39  \n",
            "1    3.555854e-38  \n",
            "2    1.009699e-35  \n",
            "42   1.650941e-33  \n",
            "25   7.115884e-33  \n",
            "28   1.378040e-28  \n",
            "45   2.484899e-28  \n",
            "43   4.292642e-28  \n",
            "44   7.217742e-28  \n",
            "27   1.367634e-27  \n",
            "26   6.359560e-27  \n",
            "87   2.414743e-25  \n",
            "105  5.379497e-25  \n",
            "82   6.101595e-25  \n",
            "107  1.106877e-23  \n",
            "9    7.886993e-14  \n",
            "106  1.967945e-09  \n",
            "83   3.591586e-09  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PART 2: MODEL-BASED FEATURE SELECTION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PART 2: MODEL-BASED FEATURE SELECTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Logistic Regression Coefficients\n",
        "print(\"\\n1. LOGISTIC REGRESSION COEFFICIENTS\")\n",
        "print(\"-\" * 80)\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "logreg_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'coefficient': logreg.coef_[0],\n",
        "    'abs_coefficient': np.abs(logreg.coef_[0])\n",
        "}).sort_values('abs_coefficient', ascending=False)\n",
        "print(\"Top 20 features by Logistic Regression coefficient:\")\n",
        "print(logreg_df.head(20))\n",
        "print(f\"Logistic Regression CV Score: {cross_val_score(logreg, X_train, y_train, cv=5).mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QisNgrzmdTc",
        "outputId": "8bd22008-8496-43d6-f77a-650d71da8735"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PART 2: MODEL-BASED FEATURE SELECTION\n",
            "================================================================================\n",
            "\n",
            "1. LOGISTIC REGRESSION COEFFICIENTS\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Logistic Regression coefficient:\n",
            "                              feature  coefficient  abs_coefficient\n",
            "48                            3pd_pct    -0.680532         0.680532\n",
            "84          elite_outcome_probability    -0.543940         0.543940\n",
            "31                             3p_pct    -0.543428         0.543428\n",
            "58                     def_3pt_fg_pct     0.466337         0.466337\n",
            "65      three_point_volume_efficiency     0.399329         0.399329\n",
            "41                     off_3pt_fg_pct     0.377064         0.377064\n",
            "94  def_three_point_volume_efficiency     0.360178         0.360178\n",
            "13                          raw_tempo     0.358993         0.358993\n",
            "28                         torvik_off     0.290003         0.290003\n",
            "8                          3man_dprpg    -0.263576         0.263576\n",
            "64               perimeter_efficiency     0.253559         0.253559\n",
            "63                     rim_efficiency    -0.236050         0.236050\n",
            "93           def_perimeter_efficiency     0.223112         0.223112\n",
            "18                   off_close2_share     0.222538         0.222538\n",
            "17                     off_dunk_share     0.218725         0.218725\n",
            "22                   def_close2_share     0.216233         0.216233\n",
            "14                          adj_tempo    -0.205454         0.205454\n",
            "75                    tempo_advantage    -0.205454         0.205454\n",
            "6                           3man_prpg    -0.178699         0.178699\n",
            "24                      def_3pt_share    -0.165282         0.165282\n",
            "Logistic Regression CV Score: 0.7224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Lasso (L1 Regularization)\n",
        "print(\"\\n2. LASSO (L1 REGULARIZATION)\")\n",
        "print(\"-\" * 80)\n",
        "lasso = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "lasso_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'coefficient': lasso.coef_,\n",
        "    'abs_coefficient': np.abs(lasso.coef_)\n",
        "}).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "non_zero_features = lasso_df[lasso_df['coefficient'] != 0]\n",
        "print(f\"Lasso selected {len(non_zero_features)} non-zero features\")\n",
        "print(\"Top 20 features by Lasso coefficient:\")\n",
        "print(lasso_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYhpXxvfmVVf",
        "outputId": "6e7d35f9-e109-4eb4-d339-76c492808b98"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. LASSO (L1 REGULARIZATION)\n",
            "--------------------------------------------------------------------------------\n",
            "Lasso selected 5 non-zero features\n",
            "Top 20 features by Lasso coefficient:\n",
            "                 feature   coefficient  abs_coefficient\n",
            "0               5man_bpm  1.067450e-02     1.067450e-02\n",
            "3             kenpom_rtg  3.803954e-03     3.803954e-03\n",
            "12                 bench -2.665450e-03     2.665450e-03\n",
            "80  free_throw_advantage -1.039083e-05     1.039083e-05\n",
            "73   bench_scoring_ratio -3.126047e-17     3.126047e-17\n",
            "5              5man_prpg -0.000000e+00     0.000000e+00\n",
            "4             torvik_rtg  0.000000e+00     0.000000e+00\n",
            "7             5man_dprpg -0.000000e+00     0.000000e+00\n",
            "8             3man_dprpg -0.000000e+00     0.000000e+00\n",
            "9                   size  0.000000e+00     0.000000e+00\n",
            "6              3man_prpg -0.000000e+00     0.000000e+00\n",
            "1               3man_bpm  0.000000e+00     0.000000e+00\n",
            "11            experience -0.000000e+00     0.000000e+00\n",
            "13             raw_tempo -0.000000e+00     0.000000e+00\n",
            "14             adj_tempo -0.000000e+00     0.000000e+00\n",
            "15                   3pr -0.000000e+00     0.000000e+00\n",
            "16                  3prd -0.000000e+00     0.000000e+00\n",
            "17        off_dunk_share  0.000000e+00     0.000000e+00\n",
            "18      off_close2_share -0.000000e+00     0.000000e+00\n",
            "19        off_far2_share  0.000000e+00     0.000000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Random Forest Feature Importance\n",
        "print(\"\\n3. RANDOM FOREST FEATURE IMPORTANCE\")\n",
        "print(\"-\" * 80)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "print(\"Top 20 features by Random Forest importance:\")\n",
        "print(rf_df.head(20))\n",
        "print(f\"Random Forest CV Score: {cross_val_score(rf, X_train, y_train, cv=5).mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSu8dpHhm9Dg",
        "outputId": "af34909e-3cdf-40d6-f64c-f4985abb482c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. RANDOM FOREST FEATURE IMPORTANCE\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Random Forest importance:\n",
            "                            feature  importance\n",
            "1                          3man_bpm    0.053067\n",
            "0                          5man_bpm    0.039678\n",
            "43                        3man_dbpm    0.034397\n",
            "2                               wab    0.033530\n",
            "4                        torvik_rtg    0.033235\n",
            "3                        kenpom_rtg    0.028584\n",
            "25                        5man_obpm    0.026290\n",
            "42                        5man_dbpm    0.024249\n",
            "45                       torvik_def    0.019566\n",
            "82   experience_weighted_production    0.019147\n",
            "26                        3man_obpm    0.018626\n",
            "27                       kenpom_off    0.018202\n",
            "28                       torvik_off    0.017244\n",
            "53                         astd_pct    0.014097\n",
            "107        def_lineup_depth_quality    0.013409\n",
            "73              bench_scoring_ratio    0.012671\n",
            "12                            bench    0.011934\n",
            "9                              size    0.011762\n",
            "75                  tempo_advantage    0.011263\n",
            "36                          ast_pct    0.011181\n",
            "Random Forest CV Score: 0.7126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Gradient Boosting Feature Importance\n",
        "print(\"\\n4. GRADIENT BOOSTING FEATURE IMPORTANCE\")\n",
        "print(\"-\" * 80)\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "gb_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': gb.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "print(\"Top 20 features by Gradient Boosting importance:\")\n",
        "print(gb_df.head(20))\n",
        "print(f\"Gradient Boosting CV Score: {cross_val_score(gb, X_train, y_train, cv=5).mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i93OJlqnU1d",
        "outputId": "69adff7d-5a53-4e66-81f0-0672a8a24e3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. GRADIENT BOOSTING FEATURE IMPORTANCE\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Gradient Boosting importance:\n",
            "                       feature  importance\n",
            "3                   kenpom_rtg    0.118558\n",
            "1                     3man_bpm    0.084890\n",
            "4                   torvik_rtg    0.073947\n",
            "43                   3man_dbpm    0.061135\n",
            "53                    astd_pct    0.043356\n",
            "0                     5man_bpm    0.038437\n",
            "26                   3man_obpm    0.031143\n",
            "36                     ast_pct    0.030099\n",
            "12                       bench    0.029763\n",
            "56           def_close2_fg_pct    0.020345\n",
            "85     offense_defense_balance    0.016377\n",
            "107   def_lineup_depth_quality    0.016214\n",
            "76   effective_possession_rate    0.016093\n",
            "14                   adj_tempo    0.014264\n",
            "69            paint_touch_rate    0.013087\n",
            "45                  torvik_def    0.012289\n",
            "35                     orb_pct    0.012151\n",
            "87        lineup_depth_quality    0.012142\n",
            "74            rotation_balance    0.011465\n",
            "73         bench_scoring_ratio    0.011321\n",
            "Gradient Boosting CV Score: 0.7028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Permutation Importance (Random Forest)\n",
        "print(\"\\n5. PERMUTATION IMPORTANCE (RANDOM FOREST)\")\n",
        "print(\"-\" * 80)\n",
        "perm = permutation_importance(rf, X_train, y_train, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "perm_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': perm.importances_mean,\n",
        "    'std': perm.importances_std\n",
        "}).sort_values('importance', ascending=False)\n",
        "print(\"Top 20 features by Permutation Importance:\")\n",
        "print(perm_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVt6osLLndO0",
        "outputId": "dc2b6381-8f32-40b2-ebee-adc0e983d3b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. PERMUTATION IMPORTANCE (RANDOM FOREST)\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 features by Permutation Importance:\n",
            "             feature  importance       std\n",
            "27        kenpom_off    0.000591  0.000902\n",
            "0           5man_bpm    0.000000  0.000000\n",
            "2                wab    0.000000  0.000000\n",
            "1           3man_bpm    0.000000  0.000000\n",
            "4         torvik_rtg    0.000000  0.000000\n",
            "5          5man_prpg    0.000000  0.000000\n",
            "6          3man_prpg    0.000000  0.000000\n",
            "7         5man_dprpg    0.000000  0.000000\n",
            "8         3man_dprpg    0.000000  0.000000\n",
            "9               size    0.000000  0.000000\n",
            "10            height    0.000000  0.000000\n",
            "3         kenpom_rtg    0.000000  0.000000\n",
            "11        experience    0.000000  0.000000\n",
            "12             bench    0.000000  0.000000\n",
            "14         adj_tempo    0.000000  0.000000\n",
            "13         raw_tempo    0.000000  0.000000\n",
            "16              3prd    0.000000  0.000000\n",
            "17    off_dunk_share    0.000000  0.000000\n",
            "18  off_close2_share    0.000000  0.000000\n",
            "15               3pr    0.000000  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Recursive Feature Elimination (Logistic Regression)\n",
        "print(\"\\n6. RFE (LOGISTIC REGRESSION) - TOP 20\")\n",
        "print(\"-\" * 80)\n",
        "rfe = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=20)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "rfe_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'selected': rfe.support_,\n",
        "    'ranking': rfe.ranking_\n",
        "}).sort_values('ranking')\n",
        "rfe_selected = rfe_df[rfe_df['selected']]['feature'].tolist()\n",
        "print(f\"RFE selected features ({len(rfe_selected)}):\")\n",
        "print(rfe_selected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZOQg6nOnmx4",
        "outputId": "5a18fd7a-f206-4e05-b0e1-df7f0e7cc6f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "6. RFE (LOGISTIC REGRESSION) - TOP 20\n",
            "--------------------------------------------------------------------------------\n",
            "RFE selected features (20):\n",
            "['3man_bpm', '3man_prpg', 'experience', 'size', 'raw_tempo', 'adj_tempo', 'efg_pct', '3p_pct', '2p_pct', 'off_3pt_fg_pct', 'efgd_pct', 'def_3pt_fg_pct', '3pd_pct', '2pd_pct', 'tempo_advantage', 'top5_rebounding_concentration', 'elite_outcome_probability', 'size_speed_index', 'def_rim_to_three_ratio', 'def_size_speed_index']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PART 3: XGBOOST METHODS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PART 3: XGBOOST FEATURE SELECTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Baseline XGBoost\n",
        "print(\"\\n1. BASELINE XGBOOST\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def baseline_xgboost(params=None):\n",
        "    if params is None:\n",
        "        params = {\n",
        "            'max_depth': 6,\n",
        "            'learning_rate': 0.1,\n",
        "            'n_estimators': 100,\n",
        "            'random_state': 42,\n",
        "            'eval_metric': 'logloss'\n",
        "        }\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"  Train Accuracy: {model.score(X_train, y_train):.4f}\")\n",
        "    print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "    print(f\"  Test Accuracy: {model.score(X_test, y_test):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "baseline_model = baseline_xgboost()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t6Ia6QtoUmp",
        "outputId": "8cc6d9b0-0e3c-400e-f922-e3a85663199b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PART 3: XGBOOST FEATURE SELECTION\n",
            "================================================================================\n",
            "\n",
            "1. BASELINE XGBOOST\n",
            "--------------------------------------------------------------------------------\n",
            "  Train Accuracy: 1.0000\n",
            "  CV Accuracy: 0.6929 (+/- 0.0164)\n",
            "  Test Accuracy: 0.7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. XGBoost Feature Importance (All Types)\n",
        "print(\"\\n2. XGBOOST FEATURE IMPORTANCE\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def get_feature_importance(model, importance_type='builtin'):\n",
        "    if importance_type == 'builtin':\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_cols,\n",
        "            'importance': model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "    else:\n",
        "        booster = model.get_booster()\n",
        "        importance_dict = booster.get_score(importance_type=importance_type)\n",
        "\n",
        "        importance_list = []\n",
        "        for fname in feature_cols:\n",
        "            importance_list.append({\n",
        "                'feature': fname,\n",
        "                'importance': importance_dict.get(fname, 0.0)\n",
        "            })\n",
        "\n",
        "        importance_df = pd.DataFrame(importance_list).sort_values('importance', ascending=False)\n",
        "\n",
        "    return importance_df\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, n_estimators=100)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "builtin_imp = get_feature_importance(xgb_model, 'builtin')\n",
        "gain_imp = get_feature_importance(xgb_model, 'gain')\n",
        "weight_imp = get_feature_importance(xgb_model, 'weight')\n",
        "cover_imp = get_feature_importance(xgb_model, 'cover')\n",
        "\n",
        "print(\"Top 20 by builtin (feature_importances_):\")\n",
        "print(builtin_imp.head(20))\n",
        "print(\"\\nTop 20 by gain:\")\n",
        "print(gain_imp.head(20))\n",
        "print(\"\\nTop 20 by weight:\")\n",
        "print(weight_imp.head(20))\n",
        "print(\"\\nTop 20 by cover:\")\n",
        "print(cover_imp.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd4D3FfNodCq",
        "outputId": "767e3955-65bd-4799-a1ad-7c740691a967"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. XGBOOST FEATURE IMPORTANCE\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 by builtin (feature_importances_):\n",
            "                               feature  importance\n",
            "3                           kenpom_rtg    0.128757\n",
            "1                             3man_bpm    0.094647\n",
            "0                             5man_bpm    0.064335\n",
            "4                           torvik_rtg    0.042778\n",
            "65       three_point_volume_efficiency    0.025646\n",
            "35                             orb_pct    0.016548\n",
            "100        defensive_versatility_score    0.015750\n",
            "39                   off_close2_fg_pct    0.014929\n",
            "42                           5man_dbpm    0.014407\n",
            "25                           5man_obpm    0.013514\n",
            "2                                  wab    0.013001\n",
            "16                                3prd    0.012906\n",
            "26                           3man_obpm    0.012846\n",
            "105              def_experience_impact    0.012315\n",
            "77         offensive_versatility_score    0.011952\n",
            "12                               bench    0.011819\n",
            "21                      def_dunk_share    0.011700\n",
            "94   def_three_point_volume_efficiency    0.011393\n",
            "50                                ftrd    0.011312\n",
            "14                           adj_tempo    0.010899\n",
            "\n",
            "Top 20 by gain:\n",
            "                               feature  importance\n",
            "3                           kenpom_rtg   18.056610\n",
            "1                             3man_bpm   13.273190\n",
            "0                             5man_bpm    9.022243\n",
            "4                           torvik_rtg    5.999090\n",
            "65       three_point_volume_efficiency    3.596592\n",
            "35                             orb_pct    2.320595\n",
            "100        defensive_versatility_score    2.208692\n",
            "39                   off_close2_fg_pct    2.093579\n",
            "42                           5man_dbpm    2.020417\n",
            "25                           5man_obpm    1.895135\n",
            "2                                  wab    1.823257\n",
            "16                                3prd    1.809878\n",
            "26                           3man_obpm    1.801507\n",
            "105              def_experience_impact    1.726995\n",
            "77         offensive_versatility_score    1.676118\n",
            "12                               bench    1.657538\n",
            "21                      def_dunk_share    1.640786\n",
            "94   def_three_point_volume_efficiency    1.597671\n",
            "50                                ftrd    1.586418\n",
            "14                           adj_tempo    1.528504\n",
            "\n",
            "Top 20 by weight:\n",
            "                       feature  importance\n",
            "53                    astd_pct        32.0\n",
            "36                     ast_pct        28.0\n",
            "12                       bench        28.0\n",
            "43                   3man_dbpm        22.0\n",
            "84   elite_outcome_probability        21.0\n",
            "49                     ftd_pct        20.0\n",
            "4                   torvik_rtg        20.0\n",
            "14                   adj_tempo        18.0\n",
            "107   def_lineup_depth_quality        16.0\n",
            "41              off_3pt_fg_pct        16.0\n",
            "29                     efg_pct        15.0\n",
            "26                   3man_obpm        15.0\n",
            "32                      ft_pct        15.0\n",
            "74            rotation_balance        15.0\n",
            "104       def_block_efficiency        15.0\n",
            "76   effective_possession_rate        15.0\n",
            "10                      height        14.0\n",
            "1                     3man_bpm        14.0\n",
            "56           def_close2_fg_pct        13.0\n",
            "96      def_rim_to_three_ratio        13.0\n",
            "\n",
            "Top 20 by cover:\n",
            "                           feature  importance\n",
            "3                       kenpom_rtg   57.838345\n",
            "0                         5man_bpm   44.838715\n",
            "1                         3man_bpm   35.912815\n",
            "4                       torvik_rtg   31.474360\n",
            "26                       3man_obpm   19.765772\n",
            "84       elite_outcome_probability   19.259426\n",
            "65   three_point_volume_efficiency   17.828379\n",
            "14                       adj_tempo   17.023706\n",
            "43                       3man_dbpm   16.560333\n",
            "19                  off_far2_share   16.133799\n",
            "45                      torvik_def   16.090298\n",
            "77     offensive_versatility_score   14.994288\n",
            "21                  def_dunk_share   13.568552\n",
            "25                       5man_obpm   13.207556\n",
            "35                         orb_pct   13.196832\n",
            "76       effective_possession_rate   13.025051\n",
            "52                         drb_pct   13.009959\n",
            "39               off_close2_fg_pct   11.862887\n",
            "106     def_four_factors_composite   11.550392\n",
            "53                        astd_pct   11.464262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. XGBoost Permutation Importance\n",
        "print(\"\\n3. XGBOOST PERMUTATION IMPORTANCE\")\n",
        "print(\"-\" * 80)\n",
        "xgb_perm = permutation_importance(xgb_model, X_train, y_train, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "xgb_perm_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': xgb_perm.importances_mean,\n",
        "    'std': xgb_perm.importances_std\n",
        "}).sort_values('importance', ascending=False)\n",
        "print(\"Top 20 by XGBoost Permutation Importance:\")\n",
        "print(xgb_perm_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS7p1wFPoqBK",
        "outputId": "b9143c86-0dbb-4407-9cbf-90253bc2bfa6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. XGBOOST PERMUTATION IMPORTANCE\n",
            "--------------------------------------------------------------------------------\n",
            "Top 20 by XGBoost Permutation Importance:\n",
            "           feature  importance       std\n",
            "53        astd_pct    0.007480  0.002120\n",
            "36         ast_pct    0.003543  0.000787\n",
            "43       3man_dbpm    0.000984  0.000984\n",
            "14       adj_tempo    0.000591  0.000902\n",
            "4       torvik_rtg    0.000000  0.000000\n",
            "5        5man_prpg    0.000000  0.000000\n",
            "6        3man_prpg    0.000000  0.000000\n",
            "7       5man_dprpg    0.000000  0.000000\n",
            "8       3man_dprpg    0.000000  0.000000\n",
            "1         3man_bpm    0.000000  0.000000\n",
            "2              wab    0.000000  0.000000\n",
            "0         5man_bpm    0.000000  0.000000\n",
            "11      experience    0.000000  0.000000\n",
            "10          height    0.000000  0.000000\n",
            "9             size    0.000000  0.000000\n",
            "12           bench    0.000000  0.000000\n",
            "16            3prd    0.000000  0.000000\n",
            "17  off_dunk_share    0.000000  0.000000\n",
            "13       raw_tempo    0.000000  0.000000\n",
            "15             3pr    0.000000  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Forward Selection\n",
        "print(\"\\n4. FORWARD SELECTION (XGBOOST)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def forward_selection(max_features=20, cv_folds=5):\n",
        "    selected = []\n",
        "    remaining = feature_cols.copy()\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    best_score = 0\n",
        "\n",
        "    for i in range(max_features):\n",
        "        best_feature = None\n",
        "        best_cv = best_score\n",
        "        best_train = 0\n",
        "\n",
        "        for feature in remaining:\n",
        "            features = selected + [feature]\n",
        "            model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "            scores = cross_val_score(model, X_train[features], y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "            if scores.mean() > best_cv:\n",
        "                best_cv = scores.mean()\n",
        "                best_feature = feature\n",
        "                model.fit(X_train[features], y_train)\n",
        "                best_train = model.score(X_train[features], y_train)\n",
        "\n",
        "        if best_feature is None:\n",
        "            break\n",
        "\n",
        "        selected.append(best_feature)\n",
        "        remaining.remove(best_feature)\n",
        "        best_score = best_cv\n",
        "\n",
        "        print(f\"  {len(selected):2d}. {best_feature:40s} Train: {best_train:.4f} | CV: {best_cv:.4f}\")\n",
        "\n",
        "    return selected\n",
        "\n",
        "forward_features = forward_selection(max_features=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNQOzIU1pXna",
        "outputId": "f22316e0-d673-4c8b-dcfe-8fe649ee95e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. FORWARD SELECTION (XGBOOST)\n",
            "--------------------------------------------------------------------------------\n",
            "   1. kenpom_rtg                               Train: 0.8169 | CV: 0.7106\n",
            "   2. torvik_def                               Train: 0.9803 | CV: 0.7283\n",
            "   3. kenpom_off                               Train: 0.9961 | CV: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Backward Elimination\n",
        "print(\"\\n5. BACKWARD ELIMINATION (XGBOOST)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def backward_elimination(min_features=15, cv_folds=5):\n",
        "    features = feature_cols.copy()\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    while len(features) > min_features:\n",
        "        worst_feature = None\n",
        "        best_cv = 0\n",
        "        best_train = 0\n",
        "\n",
        "        for feature in features:\n",
        "            test_features = [f for f in features if f != feature]\n",
        "            model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "            scores = cross_val_score(model, X_train[test_features], y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "            if scores.mean() > best_cv:\n",
        "                best_cv = scores.mean()\n",
        "                worst_feature = feature\n",
        "                model.fit(X_train[test_features], y_train)\n",
        "                best_train = model.score(X_train[test_features], y_train)\n",
        "\n",
        "        if worst_feature:\n",
        "            features.remove(worst_feature)\n",
        "            print(f\"  Removed: {worst_feature:40s} | Remaining: {len(features):2d} | Train: {best_train:.4f} | CV: {best_cv:.4f}\")\n",
        "\n",
        "    return features\n",
        "\n",
        "backward_features = backward_elimination(min_features=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G_-t9ztFpmAq",
        "outputId": "cd1fac74-48b0-4573-f143-ecc2b197312f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. BACKWARD ELIMINATION (XGBOOST)\n",
            "--------------------------------------------------------------------------------\n",
            "  Removed: bench                                    | Remaining: 107 | Train: 1.0000 | CV: 0.7165\n",
            "  Removed: block_efficiency                         | Remaining: 106 | Train: 1.0000 | CV: 0.7224\n",
            "  Removed: net_rebounding_margin                    | Remaining: 105 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: adj_tempo                                | Remaining: 104 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: net_efg_margin                           | Remaining: 103 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: net_ftr_margin                           | Remaining: 102 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: size_speed_index                         | Remaining: 101 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: def_net_turnover_margin                  | Remaining: 100 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: off_far2_fg_pct                          | Remaining: 99 | Train: 1.0000 | CV: 0.7225\n",
            "  Removed: def_net_rebounding_margin                | Remaining: 98 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: def_free_throw_advantage                 | Remaining: 97 | Train: 1.0000 | CV: 0.7342\n",
            "  Removed: def_dunk_fg_pct                          | Remaining: 96 | Train: 1.0000 | CV: 0.7303\n",
            "  Removed: off_dunk_share                           | Remaining: 95 | Train: 1.0000 | CV: 0.7304\n",
            "  Removed: def_dunk_share                           | Remaining: 94 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: def_size_speed_index                     | Remaining: 93 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: net_turnover_margin                      | Remaining: 92 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: 3pd_pct                                  | Remaining: 91 | Train: 1.0000 | CV: 0.7303\n",
            "  Removed: blk_pct                                  | Remaining: 90 | Train: 1.0000 | CV: 0.7363\n",
            "  Removed: off_3pt_share                            | Remaining: 89 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: offense_defense_balance                  | Remaining: 88 | Train: 1.0000 | CV: 0.7343\n",
            "  Removed: ftr                                      | Remaining: 87 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: def_mid_range_reliance                   | Remaining: 86 | Train: 1.0000 | CV: 0.7283\n",
            "  Removed: 3p_pct                                   | Remaining: 85 | Train: 1.0000 | CV: 0.7244\n",
            "  Removed: def_far2_fg_pct                          | Remaining: 84 | Train: 1.0000 | CV: 0.7343\n",
            "  Removed: efgd_pct                                 | Remaining: 83 | Train: 1.0000 | CV: 0.7363\n",
            "  Removed: def_perimeter_efficiency                 | Remaining: 82 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: off_3pt_fg_pct                           | Remaining: 81 | Train: 1.0000 | CV: 0.7381\n",
            "  Removed: off_close2_share                         | Remaining: 80 | Train: 1.0000 | CV: 0.7363\n",
            "  Removed: def_experience_impact                    | Remaining: 79 | Train: 1.0000 | CV: 0.7343\n",
            "  Removed: rim_efficiency                           | Remaining: 78 | Train: 1.0000 | CV: 0.7401\n",
            "  Removed: 2pd_pct                                  | Remaining: 77 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: raw_tempo                                | Remaining: 76 | Train: 1.0000 | CV: 0.7421\n",
            "  Removed: def_net_ftr_margin                       | Remaining: 75 | Train: 1.0000 | CV: 0.7381\n",
            "  Removed: def_close2_share                         | Remaining: 74 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: mid_range_reliance                       | Remaining: 73 | Train: 1.0000 | CV: 0.7382\n",
            "  Removed: def_lineup_depth_quality                 | Remaining: 72 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: rotation_balance                         | Remaining: 71 | Train: 1.0000 | CV: 0.7283\n",
            "  Removed: 5man_dprpg                               | Remaining: 70 | Train: 1.0000 | CV: 0.7264\n",
            "  Removed: shot_quality_variance                    | Remaining: 69 | Train: 1.0000 | CV: 0.7421\n",
            "  Removed: def_assist_suppression                   | Remaining: 68 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: 5man_bpm                                 | Remaining: 67 | Train: 1.0000 | CV: 0.7303\n",
            "  Removed: assist_to_usage_ratio                    | Remaining: 66 | Train: 1.0000 | CV: 0.7341\n",
            "  Removed: tempo_advantage                          | Remaining: 65 | Train: 1.0000 | CV: 0.7361\n",
            "  Removed: kenpom_off                               | Remaining: 64 | Train: 1.0000 | CV: 0.7401\n",
            "  Removed: top5_scoring_concentration               | Remaining: 63 | Train: 1.0000 | CV: 0.7342\n",
            "  Removed: experience_weighted_production           | Remaining: 62 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: 3man_prpg                                | Remaining: 61 | Train: 1.0000 | CV: 0.7341\n",
            "  Removed: 3pr                                      | Remaining: 60 | Train: 1.0000 | CV: 0.7343\n",
            "  Removed: 2p_pct                                   | Remaining: 59 | Train: 1.0000 | CV: 0.7263\n",
            "  Removed: shooting_variance_resilience             | Remaining: 58 | Train: 1.0000 | CV: 0.7421\n",
            "  Removed: effective_possession_rate                | Remaining: 57 | Train: 1.0000 | CV: 0.7342\n",
            "  Removed: def_3pt_share                            | Remaining: 56 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: blked_pct                                | Remaining: 55 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: 3man_dprpg                               | Remaining: 54 | Train: 1.0000 | CV: 0.7323\n",
            "  Removed: 3man_bpm                                 | Remaining: 53 | Train: 1.0000 | CV: 0.7343\n",
            "  Removed: tord                                     | Remaining: 52 | Train: 1.0000 | CV: 0.7382\n",
            "  Removed: four_factors_composite                   | Remaining: 51 | Train: 1.0000 | CV: 0.7441\n",
            "  Removed: kenpom_def                               | Remaining: 50 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: def_3pt_fg_pct                           | Remaining: 49 | Train: 1.0000 | CV: 0.7421\n",
            "  Removed: off_far2_share                           | Remaining: 48 | Train: 1.0000 | CV: 0.7362\n",
            "  Removed: torvik_off                               | Remaining: 47 | Train: 1.0000 | CV: 0.7421\n",
            "  Removed: def_three_point_volume_efficiency        | Remaining: 46 | Train: 1.0000 | CV: 0.7381\n",
            "  Removed: size                                     | Remaining: 45 | Train: 1.0000 | CV: 0.7421\n",
            "  Removed: ftd_pct                                  | Remaining: 44 | Train: 1.0000 | CV: 0.7401\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1843108878.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mbackward_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_elimination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1843108878.py\u001b[0m in \u001b[0;36mbackward_elimination\u001b[0;34m(min_features, cv_folds)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logloss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_cv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1804\u001b[0m             )\n\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1807\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             _check_call(\n\u001b[0;32m-> 2434\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2435\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. RFE with XGBoost\n",
        "print(\"\\n6. RFE (XGBOOST)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def rfe_xgboost(n_features=20, step=5, cv_folds=5):\n",
        "    features = feature_cols.copy()\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    while len(features) > n_features:\n",
        "        model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "        model.fit(X_train[features], y_train)\n",
        "\n",
        "        train_score = model.score(X_train[features], y_train)\n",
        "        scores = cross_val_score(model, X_train[features], y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "        importance = pd.DataFrame({\n",
        "            'feature': features,\n",
        "            'importance': model.feature_importances_\n",
        "        }).sort_values('importance')\n",
        "\n",
        "        n_remove = min(step, len(features) - n_features)\n",
        "        to_remove = importance.head(n_remove)['feature'].tolist()\n",
        "\n",
        "        print(f\"  Features: {len(features):2d} | Train: {train_score:.4f} | CV: {scores.mean():.4f} | Removing {n_remove}\")\n",
        "\n",
        "        for f in to_remove:\n",
        "            features.remove(f)\n",
        "\n",
        "    return features\n",
        "\n",
        "rfe_xgb_features = rfe_xgboost(n_features=20, step=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NCBnJsZqPos",
        "outputId": "0f943012-1fa6-4a00-f10e-72a0f5ee18a7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "6. RFE (XGBOOST)\n",
            "--------------------------------------------------------------------------------\n",
            "  Features: 108 | Train: 1.0000 | CV: 0.6950 | Removing 5\n",
            "  Features: 103 | Train: 1.0000 | CV: 0.6930 | Removing 5\n",
            "  Features: 98 | Train: 1.0000 | CV: 0.6969 | Removing 5\n",
            "  Features: 93 | Train: 1.0000 | CV: 0.7107 | Removing 5\n",
            "  Features: 88 | Train: 1.0000 | CV: 0.6871 | Removing 5\n",
            "  Features: 83 | Train: 1.0000 | CV: 0.6910 | Removing 5\n",
            "  Features: 78 | Train: 1.0000 | CV: 0.6929 | Removing 5\n",
            "  Features: 73 | Train: 1.0000 | CV: 0.7008 | Removing 5\n",
            "  Features: 68 | Train: 1.0000 | CV: 0.7185 | Removing 5\n",
            "  Features: 63 | Train: 1.0000 | CV: 0.7225 | Removing 5\n",
            "  Features: 58 | Train: 1.0000 | CV: 0.7225 | Removing 5\n",
            "  Features: 53 | Train: 1.0000 | CV: 0.7244 | Removing 5\n",
            "  Features: 48 | Train: 1.0000 | CV: 0.7284 | Removing 5\n",
            "  Features: 43 | Train: 1.0000 | CV: 0.7283 | Removing 5\n",
            "  Features: 38 | Train: 1.0000 | CV: 0.7047 | Removing 5\n",
            "  Features: 33 | Train: 1.0000 | CV: 0.7343 | Removing 5\n",
            "  Features: 28 | Train: 1.0000 | CV: 0.7146 | Removing 5\n",
            "  Features: 23 | Train: 1.0000 | CV: 0.7322 | Removing 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL COMPARISON - ALL METHODS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def compare_methods(feature_sets, cv_folds=5):\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for name, features in feature_sets.items():\n",
        "        model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "        model.fit(X_train[features], y_train)\n",
        "\n",
        "        train_score = model.score(X_train[features], y_train)\n",
        "        cv_scores = cross_val_score(model, X_train[features], y_train, cv=cv, scoring='accuracy')\n",
        "        test_score = model.score(X_test[features], y_test)\n",
        "\n",
        "        results.append({\n",
        "            'method': name,\n",
        "            'n_features': len(features),\n",
        "            'train': train_score,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'test': test_score\n",
        "        })\n",
        "\n",
        "        print(f\"{name:30s} | n={len(features):2d} | Train: {train_score:.4f} | CV: {cv_scores.mean():.4f} | Test: {test_score:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "feature_sets = {\n",
        "    'All Features': feature_cols,\n",
        "    'Top 20 T-Test': ttest_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 ANOVA': anova_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 Mutual Info': mi_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 Cohen\\'s d': cohens_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 Correlation': corr_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 LogReg': logreg_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 Random Forest': rf_df.head(20)['feature'].tolist(),\n",
        "    'Top 20 XGB Importance': builtin_imp.head(20)['feature'].tolist(),\n",
        "    'Forward Selection': forward_features,\n",
        "    'RFE XGBoost': rfe_xgb_features\n",
        "}\n",
        "\n",
        "comparison = compare_methods(feature_sets)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXrgqqvCGaYc",
        "outputId": "15e13ae1-33b6-4a05-e3dc-8beaec9d14e2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL COMPARISON - ALL METHODS\n",
            "================================================================================\n",
            "All Features                   | n=108 | Train: 1.0000 | CV: 0.6950 | Test: 0.7500\n",
            "Top 20 T-Test                  | n=20 | Train: 1.0000 | CV: 0.6870 | Test: 0.7500\n",
            "Top 20 ANOVA                   | n=20 | Train: 1.0000 | CV: 0.6791 | Test: 0.7266\n",
            "Top 20 Mutual Info             | n=20 | Train: 1.0000 | CV: 0.7164 | Test: 0.7734\n",
            "Top 20 Cohen's d               | n=20 | Train: 1.0000 | CV: 0.6791 | Test: 0.7266\n",
            "Top 20 Correlation             | n=20 | Train: 1.0000 | CV: 0.6791 | Test: 0.7266\n",
            "Top 20 LogReg                  | n=20 | Train: 1.0000 | CV: 0.6457 | Test: 0.7031\n",
            "Top 20 Random Forest           | n=20 | Train: 1.0000 | CV: 0.7381 | Test: 0.7734\n",
            "Top 20 XGB Importance          | n=20 | Train: 1.0000 | CV: 0.6969 | Test: 0.7500\n",
            "Forward Selection              | n= 3 | Train: 0.9961 | CV: 0.7500 | Test: 0.7422\n",
            "RFE XGBoost                    | n=20 | Train: 1.0000 | CV: 0.7126 | Test: 0.7500\n",
            "\n",
            "================================================================================\n",
            "COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Tf-TBrUG7iJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}